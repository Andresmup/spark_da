{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f463c1f-3847-4a4c-b068-e74eb449114e",
   "metadata": {},
   "source": [
    "# INPUT FILE NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ad9a61-e798-4a3c-a82c-1a3e11fa308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bda7166-d4db-4670-b7fc-21bc033a3c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/27 20:57:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e219bee1-5589-4ca6-a5e6-a9a1d528a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../datasets/data_corrupt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c6a4079-d0e5-468d-a794-9083d5864cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"id INTEGER, name STRING, gender STRING, salary INTEGER, dept STRING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a35b71f-73df-4c5a-b1ce-e043fd9621de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+------+------+-------+\n",
      "|  id|        name|gender|salary|   dept|\n",
      "+----+------------+------+------+-------+\n",
      "|   1|   Carl Mike|     m|170000|Support|\n",
      "|   2| Mikel Clark|     m|254300|     IT|\n",
      "|   7|Luis Fuentes|     m|257100|     IT|\n",
      "|   8|  Pedro Jose|     m|254300|     IT|\n",
      "|   3|   Bob Smith|     m|220000|     IT|\n",
      "|NULL|  Mary Scala|     f|230000|  Sales|\n",
      "|NULL|  Susan Liam|     f|150000|  Sales|\n",
      "|   6|     Xi Wuan|     f|150000|     IT|\n",
      "+----+------------+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"sep\",\",\").schema(schema).option(\"header\",\"true\").csv(path + \"*/*\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c27a1c-a31d-44be-a670-20295dfce7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec8662d-def1-40e4-9450-66e84deab066",
   "metadata": {},
   "source": [
    "## Check nulls id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b83df73-6e2d-42d9-833c-8e00027ddafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+------+-----+\n",
      "|  id|      name|gender|salary| dept|\n",
      "+----+----------+------+------+-----+\n",
      "|NULL|Mary Scala|     f|230000|Sales|\n",
      "|NULL|Susan Liam|     f|150000|Sales|\n",
      "+----+----------+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"id is null\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353b6837-8d35-476c-adba-b93190ea7cdb",
   "metadata": {},
   "source": [
    "## Find input file name w/null id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9fbecfa-c2ba-4c08-bdd7-bbdb4405d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import input_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38a887b5-b65e-4667-943e-aed4ea1ceacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+------+-----+--------------------------------------------------------------------------------------+\n",
      "|id  |name      |gender|salary|dept |path/file                                                                             |\n",
      "+----+----------+------+------+-----+--------------------------------------------------------------------------------------+\n",
      "|NULL|Mary Scala|f     |230000|Sales|file:///home/andresmunozpampillon/spark-files/datasets/data_corrupt/Q1/employees_2.csv|\n",
      "|NULL|Susan Liam|f     |150000|Sales|file:///home/andresmunozpampillon/spark-files/datasets/data_corrupt/Q2/employees_1.csv|\n",
      "+----+----------+------+------+-----+--------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"path/file\",input_file_name()).filter(\"id is null\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c29390b-2af1-4116-8801-e2d480525814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
