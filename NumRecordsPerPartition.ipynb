{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb1bca3-f1c9-43e3-877a-4b7a917a314c",
   "metadata": {},
   "source": [
    "# NUMBER OF RECORDS PER PARTITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390fc70-c2ea-40b5-ae5a-6ea33629f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52dfa950-4854-42af-9498-4c376156577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/20 19:16:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305bdb92-1345-49bb-85dc-5c11bb16bd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------+---+-----+\n",
      "|Year|First Name|     County|Sex|Count|\n",
      "+----+----------+-----------+---+-----+\n",
      "|2007|      ZOEY|      KINGS|  F|   11|\n",
      "|2007|      ZOEY|    SUFFOLK|  F|    6|\n",
      "|2007|      ZOEY|     MONROE|  F|    6|\n",
      "|2007|      ZOEY|       ERIE|  F|    9|\n",
      "|2007|       ZOE|     ULSTER|  F|    5|\n",
      "|2007|       ZOE|WESTCHESTER|  F|   24|\n",
      "|2007|       ZOE|      BRONX|  F|   13|\n",
      "|2007|       ZOE|   NEW YORK|  F|   55|\n",
      "|2007|       ZOE|     NASSAU|  F|   15|\n",
      "|2007|       ZOE|       ERIE|  F|    6|\n",
      "|2007|       ZOE|    SUFFOLK|  F|   14|\n",
      "|2007|       ZOE|      KINGS|  F|   34|\n",
      "|2007|       ZOE|     MONROE|  F|    9|\n",
      "|2007|       ZOE|     QUEENS|  F|   26|\n",
      "|2007|       ZOE|     ALBANY|  F|    5|\n",
      "|2007|     ZISSY|   ROCKLAND|  F|    5|\n",
      "|2007|     ZISSY|      KINGS|  F|   27|\n",
      "|2007|      ZION|      KINGS|  M|   15|\n",
      "|2007|      ZION|      BRONX|  M|   14|\n",
      "|2007|       ZEV|   ROCKLAND|  M|    6|\n",
      "+----+----------+-----------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_names = spark.read.format(\"csv\").option(\"inferschema\",True).option(\"header\",True).option(\"sep\",\",\").load(\"../datasets/baby_names.csv\")\n",
    "df_names.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5efc797d-c6fe-45c8-9674-b1bd3f7af1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52252"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6217e0-8a55-464f-8304-ef5fad134aeb",
   "metadata": {},
   "source": [
    "## Number of partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19f6fd82-ef92-47bd-a521-238aa31f0ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1ad79-cbf0-4cfd-918d-1bbc2a118f62",
   "metadata": {},
   "source": [
    "## Records per partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13e0c81e-fc4c-4553-9bdb-42d9bc240435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import spark_partition_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7657e14-f0c1-4198-924f-e2e3df28d869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|partition_id|count|\n",
      "+------------+-----+\n",
      "|           0|52252|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_names.withColumn(\"partition_id\",spark_partition_id()).groupBy(\"partition_id\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b514c-b01c-41d8-a13f-0ea841a69237",
   "metadata": {},
   "source": [
    "## Repartition to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9065c0e-1e71-446a-b6e2-3bfb04899f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names_5p = df_names.repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "754c701f-ec0f-4103-a2e3-3bd492a2e289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names_5p.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "929c855f-ca99-4744-b7c2-b6e1ca1c31ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|partition_id|count|\n",
      "+------------+-----+\n",
      "|           0|10451|\n",
      "|           1|10450|\n",
      "|           2|10450|\n",
      "|           3|10450|\n",
      "|           4|10451|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_names_5p.withColumn(\"partition_id\",spark_partition_id()).groupBy(\"partition_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec606e1-cd40-4231-a7f5-817cf2ecf28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
