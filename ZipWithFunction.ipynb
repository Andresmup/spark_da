{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6352828-9915-47b4-8d09-f8541cfa64a0",
   "metadata": {},
   "source": [
    "# ZIP WITH FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "084c870b-1946-46a8-994e-1854ae357676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31ecc81-6946-4340-b75b-026744911497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/01 14:33:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea9847a-f2d2-4a3f-8e04-b49b733a73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = [\n",
    "    (1, [1,1,1], [4,5,6]),\n",
    "    (2, [None,5,9], [0,8,None]),\n",
    "    (3, [4,2], [1,5,2,10]),\n",
    "    (4, [3,1,7,7], [2,6]),\n",
    "]\n",
    "\n",
    "schema_array = \"id INTEGER, array_1 ARRAY<INTEGER>, array_2 ARRAY<INTEGER>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7377cd-4412-459b-869d-a4138236e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------------+\n",
      "| id|     array_1|      array_2|\n",
      "+---+------------+-------------+\n",
      "|  1|   [1, 1, 1]|    [4, 5, 6]|\n",
      "|  2|[NULL, 5, 9]| [0, 8, NULL]|\n",
      "|  3|      [4, 2]|[1, 5, 2, 10]|\n",
      "|  4|[3, 1, 7, 7]|       [2, 6]|\n",
      "+---+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data=data_array,schema=schema_array)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5639871a-dd26-4448-bdfc-d0f0b00a9660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- array_1: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- array_2: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d9be36-7708-4a50-9047-8cef1c5a3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, zip_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1838e4ed-ec6c-42d2-8e8e-4733c8bcaa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_elements = lambda x,y: x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c66dae43-c7d5-4df7-ab7d-0d4dee2f8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_elements = lambda x,y: x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "393d2a40-f161-40fb-a27a-deb6e734c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_elements = lambda x,y: x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccea9ab3-75e7-4c38-9b44-1a0e2348037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------------+------------------+-------------------+-----------------------+\n",
      "|id |array_1     |array_2      |add               |mul                |pow                    |\n",
      "+---+------------+-------------+------------------+-------------------+-----------------------+\n",
      "|1  |[1, 1, 1]   |[4, 5, 6]    |[5, 6, 7]         |[4, 5, 6]          |[1.0, 1.0, 1.0]        |\n",
      "|2  |[NULL, 5, 9]|[0, 8, NULL] |[NULL, 13, NULL]  |[NULL, 40, NULL]   |[NULL, 390625.0, NULL] |\n",
      "|3  |[4, 2]      |[1, 5, 2, 10]|[5, 7, NULL, NULL]|[4, 10, NULL, NULL]|[4.0, 32.0, NULL, NULL]|\n",
      "|4  |[3, 1, 7, 7]|[2, 6]       |[5, 7, NULL, NULL]|[6, 6, NULL, NULL] |[9.0, 1.0, NULL, NULL] |\n",
      "+---+------------+-------------+------------------+-------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(\"*\",\n",
    "            zip_with(col(\"array_1\"),col(\"array_2\"),add_elements).alias(\"add\"),\n",
    "            zip_with(col(\"array_1\"),col(\"array_2\"),mul_elements).alias(\"mul\"),\n",
    "            zip_with(col(\"array_1\"),col(\"array_2\"),pow_elements).alias(\"pow\")\n",
    "         ).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
