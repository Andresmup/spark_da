{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f414fe7d-3344-4b34-9335-1ddcf5d32e19",
   "metadata": {},
   "source": [
    "# SPLIT ARRAY INTO COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e28d1d02-6aca-4a61-8e08-4d87244060e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607d05cf-5ea8-47e6-a60b-d9e3db5c6325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/28 19:33:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0a4c6e-c190-4b12-871b-a22a103514df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"AM1\", [1, 4, 19]),\n",
    "    (\"VM2\", [5, 2, 10, 6]),\n",
    "    (\"PO3\", [None, 0, 6]),\n",
    "    (\"PO3\", [2, 8]),\n",
    "]\n",
    "\n",
    "schema = \"test STRING, value ARRAY<INTEGER>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1db3176-e99e-405e-9b8c-a5a7a72e44a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "|test|        value|\n",
      "+----+-------------+\n",
      "| AM1|   [1, 4, 19]|\n",
      "| VM2|[5, 2, 10, 6]|\n",
      "| PO3| [NULL, 0, 6]|\n",
      "| PO3|       [2, 8]|\n",
      "+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0885eb0-4c36-4300-b475-2eaeab8107e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- test: string (nullable = true)\n",
      " |-- value: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea8b238-917c-4e02-8091-190af063a4d7",
   "metadata": {},
   "source": [
    "## Split Array into separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98bf08ed-ca61-492f-8f89-cacb6f666a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------+----------+----------+\n",
      "|test|first_time|second_time|third_time|forth_time|\n",
      "+----+----------+-----------+----------+----------+\n",
      "| AM1|         1|          4|        19|      NULL|\n",
      "| VM2|         5|          2|        10|         6|\n",
      "| PO3|      NULL|          0|         6|      NULL|\n",
      "| PO3|         2|          8|      NULL|      NULL|\n",
      "+----+----------+-----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"test\",df.value[0].alias(\"first_time\"),df.value[1].alias(\"second_time\"),df.value[2].alias(\"third_time\"), df.value[3].alias(\"forth_time\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbcf842-93d6-4262-bec1-a0bcfcadf8be",
   "metadata": {},
   "source": [
    "## Automate Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422e27ba-da9b-47a0-998b-c5bc811d65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import size, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2fed9e-e4c0-4974-812b-c0f33bc69eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+------------+\n",
      "|test|        value|num_elements|\n",
      "+----+-------------+------------+\n",
      "| AM1|   [1, 4, 19]|           3|\n",
      "| VM2|[5, 2, 10, 6]|           4|\n",
      "| PO3| [NULL, 0, 6]|           3|\n",
      "| PO3|       [2, 8]|           2|\n",
      "+----+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_v2 = df.select(\"test\", \"value\", size(\"value\").alias(\"num_elements\"))\n",
    "df_v2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41012729-6ebb-4d08-9ff2-2ef05d466aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "max_num_elements = df_v2.agg({\"num_elements\":\"max\"}).collect()[0][0]\n",
    "\n",
    "print(max_num_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2603c47-074c-46b4-8f1c-c28b4d467f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  split_array(df, max_num):\n",
    "    for i in range (max_num):\n",
    "        df = df.withColumn(f\"value_{i}\",df.value[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2103ddb-f150-4107-8aef-563de133634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-------+-------+-------+-------+\n",
      "|test|        value|value_0|value_1|value_2|value_3|\n",
      "+----+-------------+-------+-------+-------+-------+\n",
      "| AM1|   [1, 4, 19]|      1|      4|     19|   NULL|\n",
      "| VM2|[5, 2, 10, 6]|      5|      2|     10|      6|\n",
      "| PO3| [NULL, 0, 6]|   NULL|      0|      6|   NULL|\n",
      "| PO3|       [2, 8]|      2|      8|   NULL|   NULL|\n",
      "+----+-------------+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = split_array(df,max_num_elements)\n",
    "df_new.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
